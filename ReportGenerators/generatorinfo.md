# ReportGenerators README

## Overview
These Python scripts analyze branch predictor performance results from the CBP2025 benchmark suite. They process the `results.csv` file generated by running traces and create various analyses and visualizations.

---

## Scripts

### 1. **baselineDifficulty.py**
**Purpose:** Analyzes intrinsic hardness of different benchmark categories.

**What it does:**
- Ranks benchmarks by MPKI (Mispredictions Per Kilo Instructions) 
- Shows "difficulty" metrics: MPKI, CycWPPKI, and Misprediction Rate
- Identifies hardest and easiest benchmark categories
- Compares difficulty range across categories

**Usage:** `python baselineDifficulty.py`  
**Input:** `results.csv`  
**Output:** Console report showing benchmarks ranked by difficulty

---

### 2. **compareMPKI_vs50PercMPKI.py**
**Purpose:** Detects phase behavior in benchmarks by comparing full vs. steady-state metrics.

**What it does:**
- Compares MPKI vs 50PercMPKI for each benchmark
- Identifies benchmarks with **consistent** behavior (similar metrics throughout)
- Identifies benchmarks with **phase behavior** (different first half vs. second half)
- Uses configurable similarity/difference thresholds

**Usage:** `python compareMPKI_vs50PercMPKI.py`  
**Input:** `results.csv`  
**Output:** Console report + plots showing phase behavior patterns

---

### 3. **compareMetrics.py**
**Purpose:** Finds benchmarks with similar MPKI but different execution characteristics.

**What it does:**
- Within each category, finds benchmark pairs with:
  - Similar MPKI (similar prediction difficulty)
  - But very different Cycles (different execution behavior)
- Helps identify why two "equally hard" benchmarks perform differently
- Uses relative difference formula: `|val₁ - val₂| / max(val₁, val₂)`

**Usage:** `python compareMetrics.py`  
**Input:** `results.csv`  
**Output:** Console report showing benchmark pairs with divergent behavior

---

### 4. **generate_graphs.py**
**Purpose:** Comprehensive visualization suite for all performance metrics.

**What it does:**
- Creates misprediction rate bar charts (per category and overall)
- Generates 4-panel performance metric plots (IPC, MPKI, MR, IPC vs MPKI)
- Creates difficulty analysis scatter plots (MR vs MPKI)
- Saves all graphs as high-resolution PNG files

**Usage:** `python generate_graphs.py`  
**Input:** `results.csv`  
**Output:** Multiple PNG files in output directory showing various metrics

---

### 5. **graphComparator.py**
**Purpose:** Creates MPKI comparison plots with geometric means.

**What it does:**
- Generates side-by-side bar charts comparing MPKI vs 50PercMPKI
- Calculates and displays geometric mean lines
- Creates plots for representative benchmark mixes
- Shows which benchmarks have steady vs. variable prediction difficulty

**Usage:** `python graphComparator.py`  
**Input:** `results.csv`  
**Output:** PNG comparison charts for each workload type

---

### 6. **highesBenchMarkComparator.py**
**Purpose:** Simple wrapper to load highest-performing benchmark results.

**What it does:**
- Loads results from `highes_results.csv` 
- Appears to be incomplete or template code

**Usage:** Limited utility - wrapper only  
**Input:** `highes_results.csv`

---

### 7. **rangeOfBranchesAcrossBenchmarks.py**
**Purpose:** Analyzes branch density (BrPerCyc) across benchmark categories.

**What it does:**
- Calculates branch density statistics (min, max, median, IQR, std dev)
- Compares how "branch-heavy" different workload types are
- Shows which categories have more/fewer branches per cycle
- Creates statistical summaries and visualizations

**Usage:** `python rangeOfBranchesAcrossBenchmarks.py`  
**Input:** `results.csv`  
**Output:** Console statistics + plots showing branch density distributions

---

## Common Input Format
All scripts expect a `results.csv` file with columns:
- `Workload` (category: int, fp, compress, infra, media, web)
- `Run` (benchmark name)
- `MPKI`, `50PercMPKI` (mispredictions per 1K instructions)
- `MR`, `50PercMR` (misprediction rate %)
- `Cycles`, `50PercCycles` (execution cycles)
- `IPC`, `50PercIPC` (instructions per cycle)
- `BrPerCyc` (branches per cycle)
- `CycWPPKI` (wrong-path cycles per 1K instructions)

---

## Quick Start
```bash
# 1. Run traces to generate results
python scripts/trace_exec_training_list.py --trace_dir traces/ --results_dir results/

# 2. Analyze difficulty
python ReportGenerators/baselineDifficulty.py

# 3. Check for phase behavior
python ReportGenerators/compareMPKI_vs50PercMPKI.py

# 4. Generate all graphs
python ReportGenerators/generate_graphs.py

# 5. Analyze branch density
python ReportGenerators/rangeOfBranchesAcrossBenchmarks.py
```
